{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Free Generation\n",
        "\n",
        "上からび～ってなぞるだけ(ctrl+F9)でUIが出てくるようにはする。\n",
        "ただあえてコードは隠さない。A100の場合は下の2セルうまく変えて。"
      ],
      "metadata": {
        "id": "kDpFFP_ECz5r"
      },
      "id": "kDpFFP_ECz5r"
    },
    {
      "cell_type": "code",
      "source": [
        "#T4対応のほいーる。\n",
        "!pip -qqqq install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi4Ebj2m_fvy",
        "outputId": "04e1b1cb-ebcf-42f7-fb70-70bcd866174e"
      },
      "id": "yi4Ebj2m_fvy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.9/102.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#T4/A100対応xformersのインストール from https://github.com/brian6091/xformers-wheels/releases/tag/0.0.15.dev0%2B4c06c79\n",
        "#A100で使えてうれしいが、torchのバージョン変えるので時間がかかる\n",
        "#!pip install https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "UgZZnYzzCQba"
      },
      "id": "UgZZnYzzCQba",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5cc702da-b270-42a1-bcd1-d5beb11ee00e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T08:57:38.805804Z",
          "iopub.status.busy": "2023-02-14T08:57:38.805200Z",
          "iopub.status.idle": "2023-02-14T08:57:46.086199Z",
          "shell.execute_reply": "2023-02-14T08:57:46.085502Z",
          "shell.execute_reply.started": "2023-02-14T08:57:38.805737Z"
        },
        "tags": [],
        "id": "5cc702da-b270-42a1-bcd1-d5beb11ee00e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8451208d-da04-41ac-b266-d9e1dd4ce913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.18.0-py3-none-any.whl (14.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers\n",
            "  Downloading diffusers-0.13.0-py3-none-any.whl (716 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.3/716.3 KB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (7.1.2)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.21.6)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.6-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2023.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.25.1)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py[linkify,plugins]>=2.0.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from diffusers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from diffusers) (2022.6.2)\n",
            "Collecting huggingface-hub>=0.10.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from diffusers) (6.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Collecting starlette<0.26.0,>=0.25.0\n",
            "  Downloading starlette-0.25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->diffusers) (3.13.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from python-multipart->gradio) (1.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (2.10)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Collecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.10.2)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=184bf682caf97f22c4f6b62b80ac749667910bedb07846fe06976caae3bb79ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=7a56c4c29830ec85567d684ed3f5651a337b5fab9cc9bde2fba3e49ad515d865\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: tokenizers, rfc3986, pydub, ffmpy, websockets, uc-micro-py, sniffio, python-multipart, pycryptodome, orjson, mdurl, h11, aiofiles, uvicorn, markdown-it-py, linkify-it-py, huggingface-hub, anyio, accelerate, transformers, starlette, mdit-py-plugins, httpcore, diffusers, httpx, fastapi, gradio\n",
            "Successfully installed accelerate-0.16.0 aiofiles-23.1.0 anyio-3.6.2 diffusers-0.13.0 fastapi-0.92.0 ffmpy-0.3.0 gradio-3.18.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 huggingface-hub-0.12.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.6 pycryptodome-3.17 pydub-0.25.1 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.25.0 tokenizers-0.13.2 transformers-4.26.1 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "#必要ライブラリ\n",
        "!pip install gradio diffusers accelerate transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wdtaggerとpfg重みを一気にダウンロード\n",
        "!sudo apt update\n",
        "!sudo apt install git-lfg\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/SmilingWolf/wd-v1-4-vit-tagger-v2\n",
        "!wget https://huggingface.co/furusu/PFG/resolve/main/pfg-wd14-n10.pt"
      ],
      "metadata": {
        "id": "Qf_UMu_wCCV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad594a9-84a1-4ad2-e494-9de09d94c4be"
      },
      "id": "Qf_UMu_wCCV5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\u001b[0m\r                                                                               \rHit:6 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "\u001b[33m\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                    \rHit:7 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,970 kB]\n",
            "Fetched 3,306 kB in 2s (1,528 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "\u001b[1;31mE: \u001b[0mUnable to locate package git-lfg\u001b[0m\n",
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'wd-v1-4-vit-tagger-v2'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), 112.29 KiB | 8.64 MiB/s, done.\n",
            "Filtering content: 100% (5/5), 715.86 MiB | 42.15 MiB/s, done.\n",
            "--2023-02-18 00:50:36--  https://huggingface.co/furusu/PFG/resolve/main/pfg-wd14-n10.pt\n",
            "Resolving huggingface.co (huggingface.co)... 54.235.118.239, 3.231.67.228, 2600:1f18:147f:e800:671:b733:ecf3:a585, ...\n",
            "Connecting to huggingface.co (huggingface.co)|54.235.118.239|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/cc/4e/cc4e09d1446167e8d7bf7dd196e05be4bb267c7c67640214900814ce600bfb99/a953c551333cd11abb53dffda6c2593b3a787226aa2759daf584f71c724edab1?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pfg-wd14-n10.pt%3B+filename%3D%22pfg-wd14-n10.pt%22%3B&Expires=1676940637&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2NjLzRlL2NjNGUwOWQxNDQ2MTY3ZThkN2JmN2RkMTk2ZTA1YmU0YmIyNjdjN2M2NzY0MDIxNDkwMDgxNGNlNjAwYmZiOTkvYTk1M2M1NTEzMzNjZDExYWJiNTNkZmZkYTZjMjU5M2IzYTc4NzIyNmFhMjc1OWRhZjU4NGY3MWM3MjRlZGFiMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NzY5NDA2Mzd9fX1dfQ__&Signature=GQuSs1CeLLLMatcIIBiIn-UpKjx835Rs8-6htA5UJspy3OLkWZMNuhzqA5x-hIiWmSnGpBZbeqTBwOKGWB0MBQeJhhyzLi-Fm9sa9QGr4d6qRCCPgzUMerZBsd%7E5-HpMCyZynJlnsk3uKii4ngCYN53GqVyxyQK9oeOKxFXTj-SCMFZy67jvQPqxy2AID772jSnSHY7t5Wh0TZi2vy24Vspnh7upsTrbwTus7ZrTPvsGBtlqfdY3yGM06bbUPTw2yOGM-HMo0NxgpuNe1HGog-9ACK8U2%7EpG-bAPALHzuPaH8cDkTi79yFm%7EMcjtG8Gv4UY-Ez0JsjNDKKF3jqoe3w__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-02-18 00:50:37--  https://cdn-lfs.huggingface.co/repos/cc/4e/cc4e09d1446167e8d7bf7dd196e05be4bb267c7c67640214900814ce600bfb99/a953c551333cd11abb53dffda6c2593b3a787226aa2759daf584f71c724edab1?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pfg-wd14-n10.pt%3B+filename%3D%22pfg-wd14-n10.pt%22%3B&Expires=1676940637&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2NjLzRlL2NjNGUwOWQxNDQ2MTY3ZThkN2JmN2RkMTk2ZTA1YmU0YmIyNjdjN2M2NzY0MDIxNDkwMDgxNGNlNjAwYmZiOTkvYTk1M2M1NTEzMzNjZDExYWJiNTNkZmZkYTZjMjU5M2IzYTc4NzIyNmFhMjc1OWRhZjU4NGY3MWM3MjRlZGFiMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2NzY5NDA2Mzd9fX1dfQ__&Signature=GQuSs1CeLLLMatcIIBiIn-UpKjx835Rs8-6htA5UJspy3OLkWZMNuhzqA5x-hIiWmSnGpBZbeqTBwOKGWB0MBQeJhhyzLi-Fm9sa9QGr4d6qRCCPgzUMerZBsd%7E5-HpMCyZynJlnsk3uKii4ngCYN53GqVyxyQK9oeOKxFXTj-SCMFZy67jvQPqxy2AID772jSnSHY7t5Wh0TZi2vy24Vspnh7upsTrbwTus7ZrTPvsGBtlqfdY3yGM06bbUPTw2yOGM-HMo0NxgpuNe1HGog-9ACK8U2%7EpG-bAPALHzuPaH8cDkTi79yFm%7EMcjtG8Gv4UY-Ez0JsjNDKKF3jqoe3w__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.66.147.100, 18.66.147.13, 18.66.147.116, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.66.147.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31499371 (30M) [binary/octet-stream]\n",
            "Saving to: ‘pfg-wd14-n10.pt’\n",
            "\n",
            "pfg-wd14-n10.pt     100%[===================>]  30.04M  23.2MB/s    in 1.3s    \n",
            "\n",
            "2023-02-18 00:50:39 (23.2 MB/s) - ‘pfg-wd14-n10.pt’ saved [31499371/31499371]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b4ed764-80ad-4033-9061-4a79727d0dd5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T08:57:46.087545Z",
          "iopub.status.busy": "2023-02-14T08:57:46.087358Z",
          "iopub.status.idle": "2023-02-14T08:57:48.430675Z",
          "shell.execute_reply": "2023-02-14T08:57:48.430017Z",
          "shell.execute_reply.started": "2023-02-14T08:57:46.087526Z"
        },
        "id": "2b4ed764-80ad-4033-9061-4a79727d0dd5",
        "outputId": "8c35fc13-aa86-4c2d-bde4-bc7a7589e460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') memory growth: True\n"
          ]
        }
      ],
      "source": [
        "#なんか知らんがこれしないとtensorflowがVRAM全部食べて死ぬ\n",
        "import tensorflow as tf\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "        print('{} memory growth: {}'.format(device, tf.config.experimental.get_memory_growth(device)))\n",
        "else:\n",
        "    print(\"Not enough GPU hardware devices available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f2087c07-60d8-4d7b-8304-e79a615ac954",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T08:57:49.836135Z",
          "iopub.status.busy": "2023-02-14T08:57:49.835344Z",
          "iopub.status.idle": "2023-02-14T08:57:50.274234Z",
          "shell.execute_reply": "2023-02-14T08:57:50.273737Z",
          "shell.execute_reply.started": "2023-02-14T08:57:49.836108Z"
        },
        "id": "f2087c07-60d8-4d7b-8304-e79a615ac954"
      },
      "outputs": [],
      "source": [
        "####このコードは@kohya-ss氏のLoRANetwork定義を参考にしています。感謝いたします。https://github.com/kohya-ss/sd-scripts/blob/main/networks/lora.py\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import os\n",
        "import itertools\n",
        "\n",
        "UNET_TARGET_REPLACE_MODULE = [\"Transformer2DModel\"] #CrossAttentionでいいかもしれないがまあいいや\n",
        "\n",
        "PREFIX_UNET = 'pfg'\n",
        "\n",
        "    \n",
        "#Network\n",
        "class PFGNetwork(torch.nn.Module):\n",
        "    def __init__(self, unet, input_size:int = 768, cross_attention_dim:int = 1024, num_tokens:int = 1) -> None:\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.cross_attention_dim = cross_attention_dim\n",
        "        self.num_tokens = num_tokens\n",
        "        \n",
        "        #inputを入れる\n",
        "        self.input = None\n",
        "        \n",
        "        #input_dim -> token_dim * num_tokens\n",
        "        self.pfg_linear = torch.nn.Linear(self.input_size, cross_attention_dim * num_tokens)\n",
        "        #unetのforward書き換え\n",
        "        self._hook_forwards(unet, UNET_TARGET_REPLACE_MODULE)\n",
        "        self.requires_grad_(True)\n",
        "        \n",
        "    #見づらいのでメソッドにしちゃう\n",
        "    #名前変えるのめんどいからloraのまま\n",
        "    def _hook_forwards(self, root_module: torch.nn.Module, target_replace_modules) -> list:\n",
        "        count = 0\n",
        "        for name, module in root_module.named_modules():\n",
        "            if module.__class__.__name__ in target_replace_modules:\n",
        "                for child_name, child_module in module.named_modules():\n",
        "                    if child_module.__class__.__name__ == \"Linear\":\n",
        "                        #to_k, to_vのみ v1は768, v2は1024\n",
        "                        if child_module.in_features == self.cross_attention_dim:\n",
        "                            count += 1\n",
        "                            child_module.forward = self._hook_forward(child_module)\n",
        "        print(f\"create PFG for U-Net: {count} modules.\")\n",
        "    \n",
        "    #forward書き換え\n",
        "    def _hook_forward(self, org_module):\n",
        "        prev_forward = org_module.forward\n",
        "        def forward(x):\n",
        "            #(b,1,dim) -> #(b,1,in_dim * tokens) \n",
        "            c = self.pfg_linear(self.input)\n",
        "            \n",
        "            #(b,1,dim) -> #(b,tokens,in_dim) \n",
        "            c = c.reshape(-1,self.num_tokens,self.cross_attention_dim)\n",
        "            \n",
        "            #生成時は違う場合が多い、その場合は(uncond+cond)*batchのため2分の1倍する。\n",
        "            if x.shape[0] != c.shape[0]:\n",
        "                c = c.repeat(x.shape[0] // 2,1,1)\n",
        "                \n",
        "            #concatenate (b,N,in_dim) + (b,tokens,in_dim)\n",
        "            if self.input.shape[0] == x.shape[0]:\n",
        "                x = torch.cat([x,c],dim = 1)\n",
        "            else: #CFG対応：diffusers pipelineでは(uncond, cond)\n",
        "                x_uncond, x_cond = x.chunk(2)\n",
        "                x_uncond = torch.cat([x_uncond,x_uncond[:,-1:,:].repeat(1,self.num_tokens,1)],dim=1) #EOSをコピー（これでいいのか知らん）\n",
        "                x_cond = torch.cat([x_cond,c],dim = 1) \n",
        "                x = torch.cat([x_uncond,x_cond])\n",
        "\n",
        "            return prev_forward(x)\n",
        "        return forward\n",
        "    \n",
        "    def prepare_optimizer_params(self, unet_lr):\n",
        "        self.requires_grad_(True)\n",
        "        param_data = {'params': self.parameters()}\n",
        "        if unet_lr is not None:\n",
        "            param_data['lr'] = unet_lr\n",
        "        \n",
        "        return [param_data]\n",
        "            \n",
        "\n",
        "    def save_weights(self, file, dtype=None):\n",
        "        state_dict = self.state_dict()\n",
        "\n",
        "        if dtype is not None:\n",
        "            for key in list(state_dict.keys()):\n",
        "                v = state_dict[key]\n",
        "                v = v.detach().clone().to(\"cpu\").to(dtype)\n",
        "                state_dict[key] = v\n",
        "\n",
        "        if os.path.splitext(file)[1] == '.safetensors':\n",
        "            from safetensors.torch import save_file\n",
        "            save_file(state_dict, file)\n",
        "        else:\n",
        "            torch.save(state_dict, file)\n",
        "    \n",
        "    def set_input(self,input_tensor:torch.Tensor) -> None:\n",
        "        self.input = input_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3eb01c17-66ff-4d5e-8d44-13e40c84a8e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T08:57:54.570098Z",
          "iopub.status.busy": "2023-02-14T08:57:54.569174Z",
          "iopub.status.idle": "2023-02-14T08:58:02.814918Z",
          "shell.execute_reply": "2023-02-14T08:58:02.814409Z",
          "shell.execute_reply.started": "2023-02-14T08:57:54.570070Z"
        },
        "id": "3eb01c17-66ff-4d5e-8d44-13e40c84a8e5",
        "outputId": "5de10604-2cf8-4402-c90e-21dc1533c6e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#WD14 taggerモデルのロードとutils\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "model = load_model(\"wd-v1-4-vit-tagger-v2\")\n",
        "model = Model(model.layers[0].input, model.layers[-3].output) #最終層手前のプーリング層の出力を使う\n",
        "\n",
        "# DanBooru IMage Utility functions\n",
        "#このコードどこを引用とすればいいか分かんない・・・\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#pil -> cv2に改変\n",
        "def smart_imread(img:Image, flag=cv2.IMREAD_UNCHANGED):\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "    return img\n",
        "\n",
        "def smart_24bit(img):\n",
        "    if img.dtype is np.dtype(np.uint16):\n",
        "        img = (img / 257).astype(np.uint8)\n",
        "\n",
        "    if len(img.shape) == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    elif img.shape[2] == 4:\n",
        "        trans_mask = img[:, :, 3] == 0\n",
        "        img[trans_mask] = [255, 255, 255, 255]\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "    return img\n",
        "\n",
        "def make_square(img, target_size):\n",
        "    old_size = img.shape[:2]\n",
        "    desired_size = max(old_size)\n",
        "    desired_size = max(desired_size, target_size)\n",
        "\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [255, 255, 255]\n",
        "    new_im = cv2.copyMakeBorder(\n",
        "        img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color\n",
        "    )\n",
        "    return new_im\n",
        "\n",
        "def smart_resize(img, size):\n",
        "    # Assumes the image has already gone through make_square\n",
        "    if img.shape[0] > size:\n",
        "        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n",
        "    elif img.shape[0] < size:\n",
        "        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5fd65a51-96a5-4dfc-a187-e01e70819ea1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T08:58:02.816552Z",
          "iopub.status.busy": "2023-02-14T08:58:02.815983Z",
          "iopub.status.idle": "2023-02-14T08:58:02.820028Z",
          "shell.execute_reply": "2023-02-14T08:58:02.819626Z",
          "shell.execute_reply.started": "2023-02-14T08:58:02.816530Z"
        },
        "id": "5fd65a51-96a5-4dfc-a187-e01e70819ea1"
      },
      "outputs": [],
      "source": [
        "#wdtaggerの推論\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "def infer(img:Image):\n",
        "    img = smart_imread(img)\n",
        "    img = smart_24bit(img)\n",
        "    img = make_square(img, 448)\n",
        "    img = smart_resize(img, 448)\n",
        "    img = img.astype(np.float32)\n",
        "    probs = model(np.array([img]), training=False)\n",
        "    return torch.tensor(probs.numpy()).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#学習したモデルはこれなのだが、SD2系の他のモデルでももしかしたらうまくいくかもしれない。\n",
        "model_id = \"hakurei/waifu-diffusion\""
      ],
      "metadata": {
        "id": "sBdWX7RREeOi"
      },
      "id": "sBdWX7RREeOi",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4badb5ec-1a40-4b63-a821-eb8590e83e96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T09:00:44.148546Z",
          "iopub.status.busy": "2023-02-14T09:00:44.147883Z",
          "iopub.status.idle": "2023-02-14T09:00:48.163582Z",
          "shell.execute_reply": "2023-02-14T09:00:48.162759Z",
          "shell.execute_reply.started": "2023-02-14T09:00:44.148521Z"
        },
        "colab": {
          "referenced_widgets": [
            "e79f2f32a7b248bf9ec851767b39c8f1",
            "2c2c3689b7e1496f9efc3b110191fe99",
            "0209365213e04ab78f0db9a1d7c7638e",
            "636d10000331440483ab06a2f4f0d3ac",
            "7b67652b7bd74025ba093bf1834fddce",
            "db097d60f7fc439a9753e3c872efd625",
            "696022914df040f9aaf87a8b8099795a",
            "9a355820fd7242bb813d0b3624e0748b",
            "e882d606a3eb478cbb0f611df23909f0",
            "f14e3075c47e400eb5a19769d48d7cd0",
            "532c308ff00940c9a76d93c7a8d07ac0"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "4badb5ec-1a40-4b63-a821-eb8590e83e96",
        "outputId": "cd181d11-683a-4e11-d622-ada223be5d3f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e79f2f32a7b248bf9ec851767b39c8f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You have disabled the safety checker for <class 'diffusers_modules.git.lpw_stable_diffusion.StableDiffusionLongPromptWeightingPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apply xformers for unet !!!\n"
          ]
        }
      ],
      "source": [
        "#Stable diffusion モデルのロード\n",
        "#かすたむすくりぷとなるものをつかう\n",
        "from diffusers import DiffusionPipeline\n",
        "device = \"cuda\"\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None,\n",
        "    custom_pipeline=\"lpw_stable_diffusion\", #なんか知らんがwebui風のプロンプト強調()[]ができるらすい\n",
        ").to(device)\n",
        "\n",
        "try:\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    pipe.enable_vae_slicing()\n",
        "    print(\"apply xformers for unet !!!\")\n",
        "except:\n",
        "    print(\"cant apply xformers. using normal unet !!!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2ce7f047-9c9c-4ce3-92d9-afa733f8e1c0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T09:00:48.975215Z",
          "iopub.status.busy": "2023-02-14T09:00:48.974938Z",
          "iopub.status.idle": "2023-02-14T09:00:49.011826Z",
          "shell.execute_reply": "2023-02-14T09:00:49.011163Z",
          "shell.execute_reply.started": "2023-02-14T09:00:48.975194Z"
        },
        "tags": [],
        "id": "2ce7f047-9c9c-4ce3-92d9-afa733f8e1c0",
        "outputId": "48ab3ca7-95c4-480b-a391-102bdb38aa7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create PFG for U-Net: 32 modules.\n",
            "loaded\n"
          ]
        }
      ],
      "source": [
        "pfg = PFGNetwork(pipe.unet, 768, 1024, 10)\n",
        "pfg.load_state_dict(torch.load(\"pfg-wd14-n10.pt\"))\n",
        "pfg.requires_grad_(False)\n",
        "pfg.to(device, dtype = torch.float16)\n",
        "print(\"loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4de458c9-5e0a-47a1-834b-a66fb45fec34",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-14T09:00:56.242533Z",
          "iopub.status.busy": "2023-02-14T09:00:56.242020Z",
          "iopub.status.idle": "2023-02-14T09:01:00.559399Z",
          "shell.execute_reply": "2023-02-14T09:01:00.558718Z",
          "shell.execute_reply.started": "2023-02-14T09:00:56.242510Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "4de458c9-5e0a-47a1-834b-a66fb45fec34",
        "outputId": "1bcfac6d-f4da-418a-a3c9-3ca01b3bc584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9e6a9387-5599-4fa8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9e6a9387-5599-4fa8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def generate(image,prompt,negative_prompt,batch_size,image_scale,width,height,steps,guidance_scale):\n",
        "    hidden_states = infer(image).to(device)\n",
        "    pfg.set_input(hidden_states * image_scale)\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        images = pipe(prompt = [prompt]*batch_size,\n",
        "                      width = width,\n",
        "                      height = height,\n",
        "                      guidance_scale=guidance_scale,\n",
        "                      num_inference_steps=steps,\n",
        "                      negative_prompt = [negative_prompt]*batch_size,\n",
        "                      ).images\n",
        "    return images\n",
        "\n",
        "demo = gr.Interface(\n",
        "    generate,\n",
        "    [gr.Image(type=\"pil\"),\n",
        "     gr.Textbox(value=\"illustration of\"),\n",
        "     gr.Textbox(value=\"worst quality, low quality, medium quality, deleted, lowres, comic, bad anatomy,bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry\"),\n",
        "     gr.Slider(1,32,value=1,step=1),\n",
        "     gr.Slider(0,2,value=1,step=0.01,label=\"pfgの強弱\"),\n",
        "     gr.Slider(256,1280,value=640,step=64),\n",
        "     gr.Slider(256,1280,value=896,step=64),\n",
        "     gr.Slider(0,50,value=50,step=1),\n",
        "     gr.Slider(0,30,value=12,step=0.5)],\n",
        "    [gr.Gallery(label='Output', show_label=False, elem_id=\"gallery\").style(grid=[2], height=\"auto\")],\n",
        "    title = \"タイトル\",\n",
        "    description = \"説明\",\n",
        "    allow_flagging='never'\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e89447-7997-4e88-a13f-059d1d72b3ee",
      "metadata": {
        "id": "d2e89447-7997-4e88-a13f-059d1d72b3ee"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e79f2f32a7b248bf9ec851767b39c8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c2c3689b7e1496f9efc3b110191fe99",
              "IPY_MODEL_0209365213e04ab78f0db9a1d7c7638e",
              "IPY_MODEL_636d10000331440483ab06a2f4f0d3ac"
            ],
            "layout": "IPY_MODEL_7b67652b7bd74025ba093bf1834fddce"
          }
        },
        "2c2c3689b7e1496f9efc3b110191fe99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db097d60f7fc439a9753e3c872efd625",
            "placeholder": "​",
            "style": "IPY_MODEL_696022914df040f9aaf87a8b8099795a",
            "value": "Fetching 15 files: 100%"
          }
        },
        "0209365213e04ab78f0db9a1d7c7638e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a355820fd7242bb813d0b3624e0748b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e882d606a3eb478cbb0f611df23909f0",
            "value": 15
          }
        },
        "636d10000331440483ab06a2f4f0d3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14e3075c47e400eb5a19769d48d7cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_532c308ff00940c9a76d93c7a8d07ac0",
            "value": " 15/15 [00:00&lt;00:00, 1044.71it/s]"
          }
        },
        "7b67652b7bd74025ba093bf1834fddce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db097d60f7fc439a9753e3c872efd625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696022914df040f9aaf87a8b8099795a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a355820fd7242bb813d0b3624e0748b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e882d606a3eb478cbb0f611df23909f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14e3075c47e400eb5a19769d48d7cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532c308ff00940c9a76d93c7a8d07ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}